{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools used in this workshop\n",
    "\n",
    "There are a number of **Python** packages we require for this workshop. Each of the packages have a specific purpose in this workshop.\n",
    "\n",
    "* [`pandas`](http://pandas.pydata.org/pandas-docs/stable/): A package which makes data analysis in Python very easy. We will be using Pandas to explore our data and perform basic data manipulation.\n",
    "* [`sklearn (scikit-learn)`](http://scikit-learn.org/stable/): Package designed to perform machine learning Python. We will use it to train and validate a logistic regression model. The model will help us understand what effect imbalanced data can have on a machine learning model.\n",
    "* [`NumPy`](http://www.numpy.org/): A popular scientific Python package which is mainly used for working with arrays. We will be using it for a few arbitrary array calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In machine learning you typically want to build a model that does what it is suppose to do.\n",
    "\n",
    "If you have an image classifier, you want your model to correctly classify images.\n",
    "\n",
    "![\"https://www.google.ca/url?sa=i&rct=j&q=&esrc=s&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwjToc6I8pDdAhVNCDQIHayCA9wQjRx6BAgBEAU&url=https%3A%2F%2Fblog.acolyer.org%2F2016%2F04%2F20%2Fimagenet-classification-with-deep-convolutional-neural-networks%2F&psig=AOvVaw3_8QOTYYyy1ixeoaof-d_z&ust=1535584557428370\"](../data/img/imagenet_example.png)\n",
    "\n",
    "So how do you determine how well your model is at doing its job?\n",
    "\n",
    "With classification, for example, people generally take the proportion of correctly classified images as the model's accuracy score.\n",
    "\n",
    "$$Accuracy = \\frac{\\#\\ of\\ correctly\\ classfied\\ images}{\\#\\ of\\ total\\ classified\\ images}$$\n",
    "\n",
    "A high accuracy score usually equates to a good model.\n",
    "\n",
    "![\"https://plot.ly/~botevmg/5/imagenet-large-scale-visual-recognition-challenge-accuracy.png\"](../data/img/imagenet_scores.png)\n",
    "\n",
    "**BUT... this is not always true...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to healthcare\n",
    "\n",
    "Let's say you develop a binary classification model that aims to determine a person's HIV status.\n",
    "\n",
    "If this model is tested on every person in Canada and yields an overall accuracy score of 99.7%, would you consider the model worthy of replacing traditional ways of testing for HIV?\n",
    "\n",
    "### **NOPE**\n",
    "\n",
    "#### **Sometimes the incorrect predictions are more important than the correct predictions**\n",
    "\n",
    "The prevelence of HIV/AIDS in Canada is 212 people per 100,000 (0.212%) [1](https://en.wikipedia.org/wiki/HIV/AIDS_in_Canada). This means that 99.788% of Canada's population is HIV negative.\n",
    "\n",
    "If your model **predicts every person in Canada to be HIV negative**, it would automatically result in an **accuracy score of 99.788%**.\n",
    "\n",
    "$$Accuracy = \\frac{\\#\\ of\\ correctly\\ classfied\\ images}{\\#\\ of\\ total\\ classified\\ images}$$\n",
    "\n",
    "$$Accuracy = \\frac{100,000-212}{100,000}$$\n",
    "\n",
    "$$Accuracy = 0.99788=99.788\\%$$\n",
    "\n",
    "The score seems good, but if we are more interested in correctly identifying HIV positive(which makes up a small portion of cases) instead of maximizing the number of correct predictions, we need to communicate this to the model is some way.\n",
    "\n",
    "We need to be careful when interpreting our models. We need to make sure that our model does what we expect it to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Imbalanced Data Conundrum\n",
    "\n",
    "Let's take another look at our hypothetical model results. This time in the form of a confusion matrix.\n",
    "\n",
    "![](../data/img/unbalanced_confusion.png)\n",
    "\n",
    "Even though our accuracy score ($99.8\\%$) seems really good, incorrectly telling 212 people they are HIV negative, is concerning.\n",
    "\n",
    "**Our model needs to predict equally well for HIV negative and HIV positive cases. Even if the probability of being HIV positive in Canada is very low.**\n",
    "\n",
    "## All predictions are equal, but some are more equal than others\n",
    "\n",
    "The only way to tell the model that it's equally important to correctly classify the minority class (HIV+ cases) as the majority class (HIV- cases), is to **increase the importance of correctly classifying the minority group**.\n",
    "\n",
    "There are multiple ways of doing this. We will be looking at the following two methods:\n",
    "\n",
    "* **Resampling data**\n",
    "    - Undersampling\n",
    "    - Oversampling\n",
    "* **Change class weights**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Thoraric Surgery Survival Rate\n",
    "\n",
    "### Introduction\n",
    "\n",
    "To make our imbalanced data problem less hypothetical, let's consider the following dataset, which can be found [here](https://archive.ics.uci.edu/ml/datasets/Thoracic+Surgery+Data).\n",
    "\n",
    "*The data was collected retrospectively at Wroclaw Thoracic Surgery Centre for **patients who underwent major lung resections for primary lung cancer in the years 2007 & 2011**. The Centre is associated with the Department of Thoracic Surgery of the Medical University of Wroclaw and Lower-Silesian Centre for Pulmonary Diseases, Poland, while the research database constitutes a part of the National Lung Cancer Registry, administered by the Institute of Tuberculosis and Pulmonary Diseases in Warsaw, Poland.*\n",
    "\n",
    "**Let's say we are a Life Insurance company, who's interested in knowing whether it is a good or bad idea to insure a potential client who will be undergoing Thoraric Surgery. If the person survives the surgery, we want to insure the client, but if there is a high probability of not surviving, we don't want to take the risk of insuring the person. We have access to the potential client's patient properties as listed below.**\n",
    "\n",
    "**Objective:** Predict whether a person who undergoes surgery, will be alive or dead 1 year after surgery.\n",
    "\n",
    "**Patient Properties:**\n",
    "\n",
    "* DGN: Diagnosis - specific combination of ICD-10 codes for primary and secondary as well multiple tumours if any (DGN3,DGN2,DGN4,DGN6,DGN5,DGN8,DGN1) \n",
    "* PRE4: Forced vital capacity - FVC (numeric) \n",
    "* PRE5: Volume that has been exhaled at the end of the first second of forced expiration - FEV1 (numeric) \n",
    "* PRE6: Performance status - Zubrod scale (PRZ2,PRZ1,PRZ0) \n",
    "* PRE7: Pain before surgery (T,F) \n",
    "* PRE8: Haemoptysis before surgery (T,F) \n",
    "* PRE9: Dyspnoea before surgery (T,F) \n",
    "* PRE10: Cough before surgery (T,F) \n",
    "* PRE11: Weakness before surgery (T,F) \n",
    "* PRE14: T in clinical TNM - size of the original tumour, from OC11 (smallest) to OC14 (largest) (OC11,OC14,OC12,OC13) \n",
    "* PRE17: Type 2 DM - diabetes mellitus (T,F) \n",
    "* PRE19: MI up to 6 months (T,F) \n",
    "* PRE25: PAD - peripheral arterial diseases (T,F) \n",
    "* PRE30: Smoking (T,F) \n",
    "* PRE32: Asthma (T,F) \n",
    "* AGE: Age at surgery (numeric) \n",
    "* Risk1Y: 1 year survival period - (T)rue value if died (T,F) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN</th>\n",
       "      <th>PRE4</th>\n",
       "      <th>PRE5</th>\n",
       "      <th>PRE6</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE14</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Risk1Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DGN2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.16</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>OC14</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>60</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.88</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC12</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.08</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>59</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.04</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.96</td>\n",
       "      <td>PRZ2</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>OC11</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>73</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DGN  PRE4  PRE5  PRE6 PRE7 PRE8 PRE9 PRE10 PRE11 PRE14 PRE17 PRE19 PRE25  \\\n",
       "0  DGN2  2.88  2.16  PRZ1    F    F    F     T     T  OC14     F     F     F   \n",
       "1  DGN3  3.40  1.88  PRZ0    F    F    F     F     F  OC12     F     F     F   \n",
       "2  DGN3  2.76  2.08  PRZ1    F    F    F     T     F  OC11     F     F     F   \n",
       "3  DGN3  3.68  3.04  PRZ0    F    F    F     F     F  OC11     F     F     F   \n",
       "4  DGN3  2.44  0.96  PRZ2    F    T    F     T     T  OC11     F     F     F   \n",
       "\n",
       "  PRE30 PRE32  AGE Risk1Yr  \n",
       "0     T     F   60       F  \n",
       "1     T     F   51       F  \n",
       "2     T     F   59       F  \n",
       "3     F     F   54       F  \n",
       "4     T     F   73       T  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients survived: 400\n",
      "Number of patients died: 70\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/thoraric_surgery.csv')\n",
    "display(data.head())\n",
    "\n",
    "survival_counts = data.Risk1Yr.value_counts()\n",
    "print(\"Number of patients survived: {}\\nNumber of patients died: {}\".format(*survival_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Transform Data\n",
    "\n",
    "To explore the imbalanced data handling methods, we will first look at a vanilla logistic regression model.\n",
    "\n",
    "Our response variable is patient survival outcome (Did a patient die or live after surgery).\n",
    "\n",
    "This means we are working with a binary classifier.\n",
    "\n",
    "There are two things we need to do before we can train our model:\n",
    "\n",
    "* Replace strings with numbers\n",
    "* Change multiclass variables to binary variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace strings with numbers\n",
    "\n",
    "We need to replace all the `\"T\"`'s and `\"F\"`'s with `1`'s and `0`'s.\n",
    "\n",
    "We can't use strings in a numeric equation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DGN</th>\n",
       "      <th>PRE4</th>\n",
       "      <th>PRE5</th>\n",
       "      <th>PRE6</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE14</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Risk1Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DGN2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.16</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>OC14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.88</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OC12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.08</td>\n",
       "      <td>PRZ1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>OC11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.04</td>\n",
       "      <td>PRZ0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OC11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DGN3</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.96</td>\n",
       "      <td>PRZ2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>OC11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DGN  PRE4  PRE5  PRE6  PRE7  PRE8  PRE9  PRE10  PRE11 PRE14  PRE17  PRE19  \\\n",
       "0  DGN2  2.88  2.16  PRZ1     0     0     0      1      1  OC14      0      0   \n",
       "1  DGN3  3.40  1.88  PRZ0     0     0     0      0      0  OC12      0      0   \n",
       "2  DGN3  2.76  2.08  PRZ1     0     0     0      1      0  OC11      0      0   \n",
       "3  DGN3  3.68  3.04  PRZ0     0     0     0      0      0  OC11      0      0   \n",
       "4  DGN3  2.44  0.96  PRZ2     0     1     0      1      1  OC11      0      0   \n",
       "\n",
       "   PRE25  PRE30  PRE32  AGE  Risk1Yr  \n",
       "0      0      1      0   60        0  \n",
       "1      0      1      0   51        0  \n",
       "2      0      1      0   59        0  \n",
       "3      0      0      0   54        0  \n",
       "4      0      1      0   73        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.replace('F', 0, inplace=True)\n",
    "data.replace('T', 1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change multiclass variables to binary variables\n",
    "\n",
    "For any model with categorical features (opposed to numeric, for example), we need to use one-hot encoding to transform multiclass categorical features to binary features.\n",
    "\n",
    "For example:\n",
    "\n",
    "*DGN: Diagnosis - specific combination of ICD-10 codes for primary and secondary as well multiple tumours if any (DGN3,DGN2,DGN4,DGN6,DGN5,DGN8,DGN1)*\n",
    "\n",
    "Instead of saying:\n",
    "\n",
    "![](../data/img/encoding_before.png)\n",
    "\n",
    "We need to say:\n",
    "\n",
    "![](../data/img/encoding_after.png)\n",
    "\n",
    "Don't worry too much about this. Just know that this is what is happening below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols = ['DGN', 'PRE6', 'PRE14']\n",
    "dummies = pd.get_dummies(data[dummy_cols])\n",
    "\n",
    "data = data.join(dummies)\n",
    "data.drop(columns=dummy_cols, inplace=True)\n",
    "data.head()\n",
    "\n",
    "# split into train and test data\n",
    "\n",
    "# patient features\n",
    "X = data.loc[:, data.columns!='Risk1Yr']\n",
    "# response variable (what we want to predict)\n",
    "y = data['Risk1Yr']\n",
    "\n",
    "# split the data into training and testing (70% of the data used for training, and 30% used for testing)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)\n",
    "data_train, data_test = train_test_split(data, test_size=0.3, random_state=1234)\n",
    "\n",
    "# we will be using the same test dataset, but change the train dataset as we go\n",
    "X_test = data_test.loc[:, data.columns!='Risk1Yr']\n",
    "y_test = data_test['Risk1Yr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Logistic Regression with data as-is\n",
    "\n",
    "As we saw above, the vast majority of patients survived ($400$ out of $470$ patients) the surgery.\n",
    "\n",
    "If we want the model to maximize the correct number of predictions(in other words, we do not attach more importance to correctly classifying a specific class), we can use train the logistic regression model on the data as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-aac534bc1ab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mconf_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconf_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconf_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# store scores for later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# initialize score dict\n",
    "scores = {}\n",
    "\n",
    "# # patient features\n",
    "# X = data.loc[:, data.columns!='Risk1Yr']\n",
    "# # response variable (what we want to predict)\n",
    "# y = data['Risk1Yr']\n",
    "\n",
    "# # split the data into training and testing (70% of the data used for training, and 30% used for testing)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)\n",
    "X_train = data_train.loc[:, data_train.columns!='Risk1Yr']\n",
    "y_train = data_train['Risk1Yr']\n",
    "\n",
    "\n",
    "# train the model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X=X_train, y = y_train)\n",
    "\n",
    "# test the model on unseen test data\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predictions)\n",
    "test_accuracy = (conf_mat[0, 0] + conf_mat[1, 1]) / np.sum(conf_mat)\n",
    "\n",
    "# store scores for later\n",
    "scores['vanilla'] = precision_recall_fscore_support(y_true=y_test, y_pred=predictions, average='binary')\n",
    "\n",
    "print('Accuracy: {0:.2f}%'.format(test_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in terms of *number of correct predictions*, our model seems to be doing quite well.\n",
    "\n",
    "Let's take a look at the confusion matrix, which will reveal a bit more about how our model does its classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Survived</th>\n",
       "      <th>Predicted_Died</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual_Survived</th>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual_Died</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted_Survived  Predicted_Died\n",
       "Actual_Survived                 114               2\n",
       "Actual_Died                      24               1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(conf_mat, index=['Actual_Survived', 'Actual_Died'], columns=['Predicted_Survived', 'Predicted_Died'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix is showing that our model rarely ever predict that a patient will die. Since it's a safer bet to predict that a patient has survived (due to the imbalance), the model choses to do this when there is a certain level of uncertainty.\n",
    "\n",
    "However, we want to make sure that our potential client is going to survive. Even though survival is more likely, if our patient has the properties similar to the small proportion of patients who typically do not survive, we want to know about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Resampling Data\n",
    "\n",
    "### Undersampling\n",
    "\n",
    "Undersampling is the process of **reducing the number of samples of the majority class** during model training.\n",
    "\n",
    "We aim to end up with a reduced number of majority class samples equal to the number of samples in the minority class.\n",
    "\n",
    "This will result in balanced data and cause the model to pay more attention to the minority class (since it now has just as many samples as the majority class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "Number of patients survived: 284\n",
      "Number of patients died: 45\n",
      "\n",
      "Undersampled, Balanced Data:\n",
      "Number of patients survived: 45\n",
      "Number of patients died: 45\n"
     ]
    }
   ],
   "source": [
    "# determine the number of samples in the minority class\n",
    "label_min_count = data_train.Risk1Yr.value_counts().min()\n",
    "# determine the label of the minority class\n",
    "label_min = data_train.Risk1Yr.value_counts().idxmin()\n",
    "\n",
    "# create data subsets for the 2 classes\n",
    "data_max_label = data_train[data_train.Risk1Yr != label_min]\n",
    "data_min_label = data_train[data_train.Risk1Yr == label_min]\n",
    "\n",
    "# reduce the number of samples in the majority class subset\n",
    "data_max_downsample = data_max_label.sample(n = label_min_count, replace=False, random_state=1234)\n",
    "\n",
    "# merge the two subsets to give us the balanced dataset\n",
    "data_balanced = data_min_label.append(data_max_downsample)\n",
    "\n",
    "survival_counts = data_train.Risk1Yr.value_counts()\n",
    "print(\"Original Data:\\nNumber of patients survived: {}\\nNumber of patients died: {}\\n\".format(*survival_counts))\n",
    "\n",
    "survival_counts = data_balanced.Risk1Yr.value_counts()\n",
    "print(\"Undersampled, Balanced Data:\\nNumber of patients survived: {}\\nNumber of patients died: {}\".format(*survival_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.99%\n"
     ]
    }
   ],
   "source": [
    "# patient features\n",
    "X_train = data_balanced.loc[:, data_balanced.columns!='Risk1Yr']\n",
    "# response variable (what we want to predict)\n",
    "y_train = data_balanced['Risk1Yr']\n",
    "\n",
    "# split the data into training and testing (70% of the data used for training, and 30% used for testing)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)\n",
    "# \n",
    "\n",
    "# train the model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X=X_train, y = y_train)\n",
    "\n",
    "# test the model on unseen test data\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predictions)\n",
    "test_accuracy = (conf_mat[0, 0] + conf_mat[1, 1]) / np.sum(conf_mat)\n",
    "\n",
    "# store scores for later\n",
    "scores['undersampling'] = precision_recall_fscore_support(y_true=y_test, y_pred=predictions, average='binary')\n",
    "\n",
    "print('Accuracy: {0:.2f}%'.format(test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Survived</th>\n",
       "      <th>Predicted_Died</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual_Survived</th>\n",
       "      <td>73</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual_Died</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted_Survived  Predicted_Died\n",
       "Actual_Survived                  73              43\n",
       "Actual_Died                      12              13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(conf_mat, index=['Actual_Survived', 'Actual_Died'], columns=['Predicted_Survived', 'Predicted_Died'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our results are more balanced, but our overall number of correct predictions has decreased quite a bit.\n",
    "\n",
    "One of the main issues here, is that we lost a lot of training data by undersampling. Since we didn't have many samples to start off with, we end up with a small training dataset.\n",
    "\n",
    "For this reason, it makes more sense to oversample, rather than undersample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling\n",
    "\n",
    "Oversampling is the process of **increasing the number of samples of the minority class** during model training.\n",
    "\n",
    "We aim to end up with a increased number of minority class samples equal to the number of samples in the majority class.\n",
    "\n",
    "This will result in balanced data and cause the model to pay more attention to the minority class (since it now has just as many samples as the majority class), while still using all the data we have available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "Number of patients survived: 284\n",
      "Number of patients died: 45\n",
      "\n",
      "Oversampled, Balanced Data:\n",
      "Number of patients survived: 284\n",
      "Number of patients died: 284\n"
     ]
    }
   ],
   "source": [
    "# determine the  number of samples in the majority class\n",
    "# y = data_train['Risk1Yr']\n",
    "label_max_count = data_train.Risk1Yr.value_counts().max()\n",
    "# determine the label of the majority class\n",
    "label_max = data_train.Risk1Yr.value_counts().idxmax()\n",
    "\n",
    "# increase the number of samples in the minority class subset\n",
    "data_min_upsample = data_min_label.sample(n = label_max_count, replace=True, random_state=1234)\n",
    "\n",
    "# merge the two subsets to give us the balanced dataset\n",
    "data_balanced = data_max_label.append(data_min_upsample)\n",
    "\n",
    "survival_counts = data_train.Risk1Yr.value_counts()\n",
    "print(\"Original Data:\\nNumber of patients survived: {}\\nNumber of patients died: {}\\n\".format(*survival_counts))\n",
    "\n",
    "survival_counts = data_balanced.Risk1Yr.value_counts()\n",
    "print(\"Oversampled, Balanced Data:\\nNumber of patients survived: {}\\nNumber of patients died: {}\".format(*survival_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.79%\n"
     ]
    }
   ],
   "source": [
    "# patient features\n",
    "X_train = data_balanced.loc[:, data_balanced.columns!='Risk1Yr']\n",
    "# response variable (what we want to predict)\n",
    "y_train = data_balanced['Risk1Yr']\n",
    "\n",
    "# split the data into training and testing (70% of the data used for trainning, and 30% used for testing)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)\n",
    "# \n",
    "\n",
    "# train the model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X=X_train, y = y_train)\n",
    "\n",
    "# test the model on unseen test data\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predictions)\n",
    "test_accuracy = (conf_mat[0, 0] + conf_mat[1, 1]) / np.sum(conf_mat)\n",
    "\n",
    "# store scores for later\n",
    "scores['oversampling'] = precision_recall_fscore_support(y_true=y_test, y_pred=predictions, average='binary')\n",
    "\n",
    "print('Accuracy: {0:.2f}%'.format(test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Survived</th>\n",
       "      <th>Predicted_Died</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual_Survived</th>\n",
       "      <td>83</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual_Died</th>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted_Survived  Predicted_Died\n",
       "Actual_Survived                  83              33\n",
       "Actual_Died                      11              14"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(conf_mat, index=['Actual_Survived', 'Actual_Died'], columns=['Predicted_Survived', 'Predicted_Died'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Change Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.25%\n"
     ]
    }
   ],
   "source": [
    "# # patient features\n",
    "# X = data.loc[:, data.columns!='Risk1Yr']\n",
    "# # response variable (what we want to predict)\n",
    "# y = data['Risk1Yr']\n",
    "\n",
    "# # split the data into training and testing (70% of the data used for training, and 30% used for testing)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)\n",
    "\n",
    "X_train = data_train.loc[:, data_train.columns!='Risk1Yr']\n",
    "y_train = data_train['Risk1Yr']\n",
    "\n",
    "# train the model\n",
    "lr = LogisticRegression(class_weight='balanced')\n",
    "lr.fit(X=X_train, y = y_train)\n",
    "\n",
    "# test the model on unseen test data\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predictions)\n",
    "test_accuracy = (conf_mat[0, 0] + conf_mat[1, 1]) / np.sum(conf_mat)\n",
    "\n",
    "# store scores for later\n",
    "scores['change_weights'] = precision_recall_fscore_support(y_true=y_test, y_pred=predictions, average='binary')\n",
    "\n",
    "print('Accuracy: {0:.2f}%'.format(test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Survived</th>\n",
       "      <th>Predicted_Died</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual_Survived</th>\n",
       "      <td>77</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual_Died</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted_Survived  Predicted_Died\n",
       "Actual_Survived                  77              39\n",
       "Actual_Died                      10              15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(conf_mat, index=['Actual_Survived', 'Actual_Died'], columns=['Predicted_Survived', 'Predicted_Died'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative metrics for measuring accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_weights</th>\n",
       "      <th>oversampling</th>\n",
       "      <th>undersampling</th>\n",
       "      <th>vanilla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.320988</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           change_weights  oversampling  undersampling   vanilla\n",
       "precision        0.277778      0.297872       0.232143  0.333333\n",
       "recall           0.600000      0.560000       0.520000  0.040000\n",
       "f1_score         0.379747      0.388889       0.320988  0.071429"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.DataFrame(scores, index=['precision', 'recall', 'f1_score', 'support'])\n",
    "scores.drop('support', inplace=True)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
